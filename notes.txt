- Far notare come si sono aggiustate le soluzioni prodotte come "vicine" di quelle
  prodotte dall'euristica.
- Far notare quanto scarsa sia la descrizione dei metodi nel paper; quindi non siamo
  sicuri di aver implementato esattamente lo stesso algoritmo degli autori.
  Per esempio:
  1. Non è chiaro come aggiustare le soluzioni dopo essere state perturbate in MOSA.
  2. Non è chiaro come si debba fare l'annealing della temperatura.
  3. Non è chiaro se in MOSA le perturbazioni debbano essere fatte globalmente su
     tutti periodi contemporaneamente o separatamente su ogni periodo.
  4. Non è specificata la probabilità usata in MOSA per l'accettazione delle soluzioni
     non dominanti.
  5. Non è chiaro come si debba calcolare la fitness in MOIWOA.
  6. Non è chiaro come si debba ordinare le soluzioni con stesso grado di ottimalità
     in MOIWOA.
- Far notare che si è usato un vettore soluzione per ogni periodo e che si è usata
  una seconda parte della soluzione di lunghezza uguale alla prima.
- Far notare che si è usata geometric cooling strategy e ... acceptance probability come
  descritte nel paper salvato in docs/ (quello di Nam e Park non era disponibile).
  Citare il paper.
- Valutare se pesare la somma delle differenze tra objective functions nel calcolo della
  acceptance probability e nel calcolo della fitness a seconda dell'importanza delle priorità
  degli obiettivi.
- Eventualmente aggiungere altri stopping criteria.
- Far notare che si sono aggiunti stopping criteria (citare paper da cui si sono presi).
- Far notare che si è usato deap per il non-dominated sorting.
- Valutare se esistano modi più efficienti per fare il non-dominated sorting (magari
  tenendo in considerazione il sorting fatto al passo precedente).
- Far notare che non si è usato gurobi.
- Far notare come si è calcolata la fitness (con standardizzazione).
- Far notare come si sono ordinate le soluzioni con stesso grado di ottimalità in MOIWOA.
- Far notare che, anche se il fatto di far riprodurre le soluzioni in base alla fitness può
  favorire soluzioni non dominanti, il troncamento delle soluzioni in base all dominanza
  corregge (si spera) questo problema. Questo, chiaramente, ammesso che il numero di soluzioni
  ecceda in numero massimo.
- Valutare se cambiare in metodo di calcolo della fitness.
- Aggiungere README.
- Aggiungere requirements.
- Aggiungere LICENSE.
- Citare deap (se usata).
- Far notare che nella risoluzione con epsilon-constraint method si è scelto il numero di trip
  per periodo arbitrariamente uguale al numero di required edges (nel caso "peggiore" un solo
  veicolo viene usato in un periodo, e tale veicolo fa un trip per ogni required edge, ergo
  il numero massimo di trip possibile è uguale al numero di required edge).
- Far notare che si è cambiato il constraint (5) togliendo la condizione dal primo e dall'ultimo
  nodo (perché il viaggio può partire e finire in quei nodi -  ci dovrebbero pensare i constraint
  (16) e (17) ai nodi di partenza e arrivo).
- Spiegare come si sono generati i valori di c, in particilare come si è formato il connected
  graph (usando networkx).
- Far notare come si è gestito il constraint (13) nel modello esatto (usando il lazy constraint
  solo sugli edge rilevanti).
- Far notare come si sono scelti i parametri del problema date le dimensioni di un problema
  (scrivere anche equazioni usate nello script).
- Far notare che il numero di epoche è ciò che rende l'ottimizzazione più onerosa computazionalmente,
  quindi per la scalabilità si è considerato il caso con T=1 fisso, e poi a parte il caso in cui T
  aumenta.
- Far notare che il tempo impiegato dall'ottimizzazione esatta dipende moltissimo dalla scelta dei
  parametri iniziali. Perciò per la scalabilità si è scelto di calcolare i parametri iniziali usando
  compute_good_parameters (senza "_random") per tutti i dataset, in modo da avere un minimo di
  senso nella scalabilità (anche perché non è chiaro come incrementare la dimensione del problema,
  visti i molti parametri).
- Far notare che i valori di epsilon si sono calcolati prendendo l'intervallo tra il best e il worst
  objective ma solo il sottointervallo tra 0.25 e 0.75. Far notare anche che l'oggetto calcolato con
  i risultati del modello stesso che lo ottimizzava è stato escluso.
- Far notare che le formule per MID e RASO del paper sono dovute essere corrette perché uno degli
  objective è massimizzato. Far notare che si è anche normalizzato MID.
- Far notare che il constraint (13) è (di gran lunga) quello che rende il modello più lento.
- Far notare come si è corretta la formula per il constraint (13): solo sottoinsiemi connessi e
  aggiustamento di right_hand_side quando il subset contiene l'origine del moto.

- Capire se quando si calcola la acceptance probability bisogna fare la differenza tra
  le objective functions del primo e del secondo o del secondo e del primo.
